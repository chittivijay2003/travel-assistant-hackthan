# =============================================================================
# TRAVEL ASSISTANT CONFIGURATION
# =============================================================================

# -----------------------------------------------------------------------------
# Google Gemini LLM Configuration (REQUIRED)
# -----------------------------------------------------------------------------
# Get your API key from: https://makersuite.google.com/app/apikey
GOOGLE_API_KEY=your_google_api_key_here
GEMINI_MODEL=models/gemini-pro-latest
# Available models: models/gemini-flash-latest, models/gemini-2.5-flash, models/gemini-2.5-pro

# -----------------------------------------------------------------------------
# Redis Configuration (OPTIONAL - for faster user history storage)
# -----------------------------------------------------------------------------
# Set USE_REDIS=true to enable Redis backend, otherwise uses JSON file storage
USE_REDIS=false
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0
REDIS_PASSWORD=

# To use Redis, install and run:
#   docker run -d -p 6379:6379 redis
# Then set USE_REDIS=true

# -----------------------------------------------------------------------------
# LangFuse Configuration (OPTIONAL - for LLM observability and tracing)
# -----------------------------------------------------------------------------
# Get your keys from: https://cloud.langfuse.com
LANGFUSE_PUBLIC_KEY=pk-lf-your_public_key_here
LANGFUSE_SECRET_KEY=sk-lf-your_secret_key_here
LANGFUSE_HOST=https://us.cloud.langfuse.com

# To enable LangFuse tracing:
# 1. Sign up at https://cloud.langfuse.com
# 2. Create a new project
# 3. Copy the public and secret keys
# 4. Add them above and restart the application
# 5. View traces in your Langfuse dashboard
#
# Features:
# - Track all LLM calls (input/output/tokens)
# - Monitor RAG policy retrievals
# - Trace memory operations
# - View complete request pipeline
# - Each request gets unique txnid for audit trails
# - Search logs by [AUDIT] to find transaction IDs

# -----------------------------------------------------------------------------
# Application Settings
# -----------------------------------------------------------------------------
# Logging level: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# LLM Temperature (0.0-1.0): Higher = more creative, Lower = more focused
TEMPERATURE=0.7
