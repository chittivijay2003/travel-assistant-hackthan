# âœˆï¸ AI Travel Assistant with LangGraph

An intelligent travel assistant powered by **LangGraph**, **Google Gemini**, **Local Embeddings**, and **RAG** that helps users plan trips, manage itineraries, and get in-trip support while ensuring compliance with company travel policies.

## ğŸŒŸ Features

### ğŸ¯ Intent-Based Routing
The system intelligently classifies user queries into four categories using Google Gemini:

1. **Information Node** ğŸ“
   - Saves user preferences and travel information
   - Smart itinerary regeneration when new preferences are added
   - Examples: "I love mountains", "I prefer vegetarian food"

2. **Itinerary Node** ğŸ—ºï¸
   - Generates personalized travel itineraries
   - Uses user history for customization
   - Examples: "Suggest a 3-day itinerary in Japan"

3. **Travel Plan Node** ğŸ›«
   - Creates complete travel plans with flights, hotels, and cabs
   - Validates against company policy using RAG
   - Policy-compliant cost breakdowns
   - Conversation-aware (remembers context across messages)
   - Examples: "Plan a 5-day trip to Tokyo with flights"

4. **Support Trip Node** ğŸ†˜
   - Provides trip modifications and support
   - Policy-compliant suggestions
   - Examples: "Change my hotel", "Add cab service for day 3"

## ğŸ—ï¸ Architecture

```
User Input â†’ Load History â†’ Intent Classification (Gemini) â†’ Route to Node
                                                             â†“
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚                                                  â”‚
            Information    Itinerary    Travel Plan    Support Trip
            Node           Node         Node           Node
                  â”‚                                                  â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                        â†“
                          Response + Save to History
```

### ğŸ”‘ Technology Stack
- **LangGraph**: Workflow orchestration with state management
- **LangChain**: LLM interaction and prompt engineering  
- **Google Gemini**: Language model (models/gemini-pro-latest)
- **all-MiniLM-L6-v2**: Local embeddings for user history and policies
- **FAISS**: Vector store for policy document retrieval (no Docker needed)
- **Langfuse**: LLM observability and tracing with transaction ID tracking
- **Streamlit**: Interactive chat UI
- **JSON + NumPy**: User history storage (Mem0 alternative)

### âœ… Key Benefits
- ğŸš€ **100% Local Embeddings** - No API calls for embeddings, zero quota issues
- ğŸ’¾ **Simple Storage** - JSON files + FAISS (no external databases)
- ğŸ”„ **Conversation Context** - Remembers full conversation history
- ğŸ“‹ **Policy Compliance** - RAG ensures all plans follow company rules
- âš¡ **Fast & Efficient** - Local embeddings + Gemini Flash
- ğŸ” **Full Observability** - Track all LLM calls, RAG queries, and operations with Langfuse

## ğŸ“‹ Prerequisites

- Python 3.10+
- Google API key (for Gemini)

## ğŸš€ Quick Start

1. **Clone the repository**
   ```bash
   git clone https://github.com/chittivijay2003/travel-assistant-hackthan.git
   cd travel-assistant-hackthan
   ```

2. **Install dependencies**
   ```bash
   pip3 install -r requirements.txt
   ```

3. **Set up environment variables**
   ```bash
   cp .env.example .env
   ```
   
   Edit `.env` and add your API keys:
   ```env
   GOOGLE_API_KEY=your_google_api_key_here
   GEMINI_MODEL=models/gemini-pro-latest
   
   # Optional: Enable Langfuse for observability
   LANGFUSE_PUBLIC_KEY=pk-lf-your_public_key_here
   LANGFUSE_SECRET_KEY=sk-lf-your_secret_key_here
   LANGFUSE_HOST=https://us.cloud.langfuse.com
   ```

4. **Create and ingest policy document**
   ```bash
   python3 create_policy.py
   ```
   This creates a company travel policy PDF and ingests it into FAISS vector store.

5. **Run the application**
   ```bash
   streamlit run app.py
   ```

The app will open in your browser at `http://localhost:8501`

## ğŸ’¬ Example Interactions

**1. Share Preferences (Information Node)**
```
User: I love trekking in the mountains
Assistant: Thank you for sharing! I've noted that: I love trekking in the mountains
```

**2. Request Itinerary (Itinerary Node)**
```
User: Suggest a 3-day itinerary in Tokyo
Assistant: [Generates detailed 3-day Tokyo itinerary based on your preferences]

User: yes, proceed with this
Assistant: [Moves to travel plan creation]
```

**3. Plan Complete Trip (Travel Plan Node)**
```
User: Plan a trip to London with flights and cabs
Assistant: I need: Travel dates, Origin, Number of travelers, Budget

User: Jan 15-20, from NYC, 1 person, $5000
Assistant: [Generates complete plan with flights, hotel, cabs - all policy compliant]
```

**4. Get Trip Support (Support Trip Node)**
```
User: Change my hotel to a cheaper option
Assistant: [Provides cheaper hotel options within company policy]
```

## ğŸ“ Project Structure

```
travel-assistant-hackthan/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ nodes/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ state.py                 # GraphState definition
â”‚   â”‚   â”œâ”€â”€ user_input.py            # Load user history from database
â”‚   â”‚   â”œâ”€â”€ intent_classification.py # Gemini-based intent classifier
â”‚   â”‚   â”œâ”€â”€ information.py           # Save preferences + smart updates
â”‚   â”‚   â”œâ”€â”€ itinerary.py             # Generate creative itineraries
â”‚   â”‚   â”œâ”€â”€ travel_plan.py           # Policy-compliant travel plans
â”‚   â”‚   â””â”€â”€ support_trip.py          # Trip modifications & support
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ logger.py                # Logging configuration
â”‚   â”‚   â”œâ”€â”€ mem0_manager.py          # User history (JSON + all-MiniLM-L6-v2)
â”‚   â”‚   â””â”€â”€ rag_manager.py           # Policy RAG (FAISS + all-MiniLM-L6-v2)
â”‚   â”œâ”€â”€ config.py                    # Environment configuration
â”‚   â””â”€â”€ workflow.py                  # LangGraph workflow orchestration
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ user_memories.json           # User history database
â”‚   â”œâ”€â”€ user_embeddings.npy          # Cached embeddings
â”‚   â”œâ”€â”€ policies/                    # Policy PDF documents
â”‚   â”‚   â””â”€â”€ company_travel_policy.pdf
â”‚   â””â”€â”€ vector_store/                # FAISS vector store
â”‚       â””â”€â”€ faiss_index/
â”œâ”€â”€ logs/                            # Application logs
â”œâ”€â”€ .env                             # Environment variables (not in git)
â”œâ”€â”€ .env.example                     # Environment template
â”œâ”€â”€ app.py                           # Streamlit UI
â”œâ”€â”€ create_policy.py                 # Policy generator & ingestion
â”œâ”€â”€ requirements.txt                 # Python dependencies
â”œâ”€â”€ ARCHITECTURE_GUIDE.md            # Detailed implementation guide
â””â”€â”€ README.md                        # This file
```

## ğŸ”§ Configuration

### Environment Variables
Edit `.env` file:

```env
# Required
GOOGLE_API_KEY=your_google_api_key_here

# Optional (defaults provided)
GEMINI_MODEL=models/gemini-pro-latest
TEMPERATURE=0.7
LOG_LEVEL=INFO
USE_REDIS=false

# Langfuse Observability (optional)
LANGFUSE_PUBLIC_KEY=pk-lf-your_public_key_here
LANGFUSE_SECRET_KEY=sk-lf-your_secret_key_here
LANGFUSE_HOST=https://us.cloud.langfuse.com
```

### Enable Langfuse Observability (Optional)
1. Sign up at [Langfuse Cloud](https://cloud.langfuse.com)
2. Create a new project
3. Copy your public and secret keys
4. Add them to `.env` file
5. Restart the application
6. View traces at your Langfuse dashboard

**Features:**
- Track all LLM calls with input/output
- Monitor RAG policy retrievals
- Trace memory operations
- View complete request flow
- Each request gets unique transaction ID (txnid) for audit trails
- Search logs by `[AUDIT]` to find transaction IDs

### Get Google API Key
1. Visit [Google AI Studio](https://makersuite.google.com/app/apikey)
2. Create a new API key
3. Add to `.env` file

### Policy Documents
- Default policy is auto-created by `create_policy.py`
- Add custom policies to `data/policies/` directory
- Policies are automatically ingested into FAISS

## ğŸ” How It Works

### 1. User Input Node
- **File**: `src/nodes/user_input.py`
- Loads last 20 user memories from JSON database
- Formats as readable history for context

### 2. Intent Classification (Gemini)
- **File**: `src/nodes/intent_classification.py`
- Uses Google Gemini (temperature=0.3 for accuracy)
- Analyzes input + conversation history
- Routes to: information | itinerary | travel_plan | support_trip

### 3. Node Processing

**Information Node** (`src/nodes/information.py`)
- Saves preferences with all-MiniLM-L6-v2 embeddings
- Smart feature: Auto-regenerates itineraries when new preferences added
- Storage: `data/user_memories.json` + `data/user_embeddings.npy`

**Itinerary Node** (`src/nodes/itinerary.py`)
- Gemini generates creative day-by-day plans (temperature=0.8)
- Uses user preferences for personalization

**Travel Plan Node** (`src/nodes/travel_plan.py`)
- Validates required info (dates, origin, travelers, budget)
- Queries RAG for policy compliance
- Gemini generates complete plan (temperature=0.7)
- Includes flights, hotels, cabs with cost breakdown

**Support Trip Node** (`src/nodes/support_trip.py`)
- Retrieves current trip from history
- Queries RAG for policy compliance
- Suggests modifications within budget

### 4. User History (Mem0 Alternative)
- **File**: `src/utils/mem0_manager.py`
- **Storage**: JSON file + NumPy embeddings
- **Embeddings**: all-MiniLM-L6-v2 (384 dimensions)
- **Benefits**: Local, fast, no API calls

**Metadata Types**:
- `preference` - User likes/dislikes
- `selection` - Confirmed itinerary choice
- `travel_plan_request` - Trip booking
- `trip_modification` - Changes to trip

### 5. RAG for Policy Compliance
- **File**: `src/utils/rag_manager.py`
- **Vector Store**: FAISS (local, no Docker)
- **Embeddings**: all-MiniLM-L6-v2 (same as Mem0)
- **Chunking**: 1000 chars with 200 char overlap

**Policy Content**:
- Flight budgets: $500 domestic, $2,500 international
- Hotel budgets: $200-300/night
- Cab allowances: $100/day
- Total trip budgets by duration

### 6. Conversation Context
- Full conversation history passed through all nodes
- Enables multi-turn interactions
- Remembers previous itineraries, confirmations, etc.

## ğŸ§ª Testing

Test different scenarios:

```python
# Information Node
"I love mountains and trekking"

# Itinerary Node  
"Suggest a 5-day itinerary in Switzerland"

# Confirm itinerary and move to travel plan
"yes, I want this plan"
"proceed with this itinerary"

# Travel Plan Node
"Plan a trip to Tokyo"
# System asks for: dates, origin, travelers, budget
"Jan 5-8, from Hyderabad, 3 travelers, $2000"
# Generates complete plan

# Support Trip Node
"Change my hotel to a cheaper option"
```

## ğŸ“Š Logging & Observability

### Local Logs
Logs in `logs/` directory:
- `workflow.log` - Graph execution (includes `[AUDIT]` transaction IDs)
- `intent_classification.log` - Intent decisions
- `travel_plan.log` - Travel planning
- `rag_manager.log` - Policy queries
- `mem0_manager.log` - User history operations
- `langfuse_manager.log` - Langfuse tracing status
- `ui.log` - Streamlit UI

### Transaction ID Tracking
Every request gets a unique transaction ID (txnid) for audit trails:
```bash
# View audit logs with transaction IDs
grep '[AUDIT]' logs/workflow.log

# Example output:
# [AUDIT] Transaction ID: txn_a1b2c3d4e5f6g7h8 - User: user_123
```

### Langfuse Dashboard
- View all traces at: https://cloud.langfuse.com
- Search by transaction ID (txnid) to see complete request flow
- Monitor LLM performance, costs, and latency
- Debug issues by tracing through pipeline execution

## ğŸ› ï¸ Troubleshooting

### Common Issues

1. **Google API key errors**
   ```bash
   # Verify your key is set
   python3 -c "from src.config import Config; Config.validate()"
   ```

2. **Import errors**
   ```bash
   pip3 install -r requirements.txt
   ```

3. **FAISS index not found**
   ```bash
   python3 create_policy.py  # Creates policy and FAISS index
   ```

4. **Slow first run**
   - First run downloads all-MiniLM-L6-v2 model (~90MB)
   - Subsequent runs are fast (model cached)

## ğŸ“– Documentation

- **ARCHITECTURE_GUIDE.md** - Complete implementation details
  - File structure and logic placement
  - Technology choices explained
  - Code examples for each component
  - Data flow diagrams

## ğŸš€ Deployment

### Local Development
```bash
streamlit run app.py
```

### Production Deployment

**Streamlit Cloud** (Easiest):
1. Push to GitHub
2. Connect at [streamlit.io/cloud](https://streamlit.io/cloud)
3. Add `GOOGLE_API_KEY` in secrets
4. Deploy!

**Docker**:
```dockerfile
FROM python:3.10-slim
WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY . .
CMD ["streamlit", "run", "app.py"]
```

**Environment Variables for Production**:
- Store `GOOGLE_API_KEY` in secrets manager
- Never commit `.env` to git
- Use `.env.example` as template

## ğŸ” Security

- âœ… `.env` is in `.gitignore`
- âœ… API keys stored in environment variables
- âœ… No hardcoded credentials
- âœ… All data stored locally

## ğŸ“ License

Educational project - MIT License

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch: `git checkout -b feature-name`
3. Commit changes: `git commit -m 'Add feature'`
4. Push: `git push origin feature-name`
5. Open pull request

## ğŸ“§ Contact

- **GitHub**: [@chittivijay2003](https://github.com/chittivijay2003)
- **Repository**: [travel-assistant-hackthan](https://github.com/chittivijay2003/travel-assistant-hackthan)

---

Built with â¤ï¸ using **LangGraph** â€¢ **Google Gemini** â€¢ **FAISS** â€¢ **all-MiniLM-L6-v2** â€¢ **Streamlit**

**Note**: This project uses `models/gemini-pro-latest` which works with the current Google Generative AI API. If you encounter model errors, verify your API key has access to the Gemini models.
